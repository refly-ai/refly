import { Source, DriveFileCategory } from '@refly/openapi-schema';
import { SkillRunnableConfig } from '../../base';
import { processQuery } from './queryProcessor';
import { ContextBlock, prepareContext } from './context';
import { SkillEngine } from '../../engine';

/**
 * Unified multimodal interpretation result
 * Returned by Gemini preprocessing for images, videos, audio, and documents
 */
export interface MultimodalInterpretation {
  /** File type category */
  type: DriveFileCategory;
  /** File ID */
  fileId: string;
  /** File name for display */
  fileName?: string;
  /** Gemini analysis/interpretation result */
  analysis: string;
}

export interface PreprocessResult {
  optimizedQuery: string;
  context: ContextBlock;
  sources?: Source[];
  usedChatHistory?: any[];
  /** Unified multimodal interpretations from Gemini preprocessing */
  multimodalInterpretations?: MultimodalInterpretation[];
}

/**
 * Multimodal file categories that can be preprocessed
 */
type MultimodalCategory = 'image' | 'video' | 'audio' | 'document';

/**
 * File info with optional content type for multimodal processing
 * contentType is passed through to avoid redundant database queries
 */
interface MultimodalFileInfo {
  fileId: string;
  fileName?: string;
  /** MIME type from drive file, passed to avoid re-querying */
  contentType?: string;
}

/**
 * Check if a category is multimodal (can be preprocessed)
 */
function isMultimodalCategory(category: string | undefined): category is MultimodalCategory {
  return (
    category === 'image' || category === 'video' || category === 'audio' || category === 'document'
  );
}

/**
 * Extract file IDs that have already been processed by upstream nodes.
 * Checks context.results for upstream ActionResults that contain files.
 *
 * This prevents re-processing files that were already analyzed in upstream workflow nodes.
 */
function getAlreadyProcessedFileIds(config: SkillRunnableConfig): Set<string> {
  const processedFileIds = new Set<string>();
  const context = config?.configurable?.context;

  if (!context?.results?.length) return processedFileIds;

  for (const resultItem of context.results) {
    const result = resultItem?.result;
    if (!result) continue;

    // Check files in the upstream result's context (files that were input to that node)
    const resultContext = result.context;
    if (resultContext?.files?.length) {
      for (const fileItem of resultContext.files) {
        if (fileItem?.fileId) {
          processedFileIds.add(fileItem.fileId);
        }
      }
    }

    // Also check files generated by the upstream result
    if (result.files?.length) {
      for (const file of result.files) {
        if (file?.fileId) {
          processedFileIds.add(file.fileId);
        }
      }
    }
  }

  return processedFileIds;
}

/**
 * Extract file IDs grouped by category from context.
 * Excludes files that have already been processed by upstream nodes.
 *
 * @param config - Skill runtime config containing context
 * @param alreadyProcessedFileIds - Set of file IDs already processed upstream (skip these)
 */
function extractFileIdsByCategory(
  config: SkillRunnableConfig,
  alreadyProcessedFileIds: Set<string> = new Set(),
): Record<MultimodalCategory, MultimodalFileInfo[]> {
  const context = config?.configurable?.context;
  const result: Record<MultimodalCategory, MultimodalFileInfo[]> = {
    image: [],
    video: [],
    audio: [],
    document: [],
  };

  if (!context) return result;

  // From context.files (DriveFile items with category)
  if (context.files?.length) {
    for (const fileItem of context.files) {
      const category = fileItem.file?.category;
      // Skip files already processed by upstream nodes
      if (
        fileItem.fileId &&
        isMultimodalCategory(category) &&
        !alreadyProcessedFileIds.has(fileItem.fileId)
      ) {
        result[category].push({
          fileId: fileItem.fileId,
          fileName: fileItem.file?.name,
          contentType: fileItem.file?.type, // MIME type from drive file
        });
      }
    }
  }

  // From context.mediaList
  if (context.mediaList?.length) {
    for (const media of context.mediaList) {
      // Skip files already processed by upstream nodes
      if (
        media.entityId &&
        isMultimodalCategory(media.mediaType) &&
        !alreadyProcessedFileIds.has(media.entityId)
      ) {
        result[media.mediaType].push({
          fileId: media.entityId,
          fileName: undefined, // mediaList doesn't have fileName
          contentType: undefined, // mediaList doesn't have contentType
        });
      }
    }
  }

  return result;
}

/**
 * Check if there are any multimodal files to process
 */
function hasMultimodalFiles(
  filesByCategory: Record<MultimodalCategory, MultimodalFileInfo[]>,
): boolean {
  return (
    filesByCategory.image.length > 0 ||
    filesByCategory.video.length > 0 ||
    filesByCategory.audio.length > 0 ||
    filesByCategory.document.length > 0
  );
}

/**
 * Build context summary for multimodal analysis
 * Provides Gemini with background context to improve analysis quality
 */
function buildContextSummary(context: ContextBlock | undefined, query: string): string {
  if (!context) return query;

  const parts: string[] = [];

  // Add user query first
  parts.push(`User Query: ${query}`);

  // Add relevant search results as context (truncated for brevity)
  if (context.results?.length) {
    const resultsSummary = context.results
      .slice(0, 3) // Limit to top 3 results
      .map((r) => `- ${r.title}: ${r.content.slice(0, 200)}...`)
      .join('\n');
    parts.push(`\nRelevant Context:\n${resultsSummary}`);
  }

  // Add file metadata if available
  if (context.files?.length) {
    const filesList = context.files
      .slice(0, 5) // Limit to 5 files
      .map((f) => `- ${f.name} (${f.type}): ${f.summary || 'No summary'}`)
      .join('\n');
    parts.push(`\nAvailable Files:\n${filesList}`);
  }

  return parts.join('\n');
}

/**
 * Process all multimodal files through Gemini APIs
 * Returns unified interpretation results, skipping failures
 *
 * Uses batch processing for all media types:
 * - Images: batchVisionRead (existing)
 * - Videos: batchVideoUnderstanding (always File API)
 * - Audio: batchAudioUnderstanding (always File API)
 * - Documents: batchDocumentProcessing (File API for >= 2MB, inline for < 2MB)
 *
 * @param filesByCategory - Files grouped by category with contentType for optimization
 * @param query - User's query
 * @param context - Prepared context with search results and file metadata
 * @param config - Skill runtime config
 * @param engine - Skill engine instance
 */
async function processMultimodalFiles(
  filesByCategory: Record<MultimodalCategory, MultimodalFileInfo[]>,
  query: string,
  context: ContextBlock | undefined,
  config: SkillRunnableConfig,
  engine: SkillEngine,
): Promise<MultimodalInterpretation[]> {
  const user = config?.configurable?.user;
  if (!user) return [];

  // Build enriched query with context for better multimodal analysis
  const enrichedQuery = buildContextSummary(context, query);

  const results: MultimodalInterpretation[] = [];
  const promises: Promise<void>[] = [];

  // Process images (batch)
  if (filesByCategory.image.length > 0 && engine.service.batchVisionRead) {
    promises.push(
      (async () => {
        try {
          const fileIds = filesByCategory.image.map((f) => f.fileId);
          const fileNames = filesByCategory.image
            .map((f) => f.fileName)
            .filter(Boolean) as string[];
          const result = await engine.service.batchVisionRead!(user, {
            fileIds,
            query: enrichedQuery || undefined,
            mode: 'general',
          });
          if (result.success && result.data?.analysis) {
            // For batch, create one combined interpretation
            results.push({
              type: 'image',
              fileId: fileIds.join(','),
              fileName: fileNames.length > 0 ? fileNames.join(', ') : undefined,
              analysis: result.data.analysis,
            });
          } else if (!result.success) {
            engine.logger.warn(
              { errCode: result.errCode, errMsg: result.errMsg },
              'Image preprocessing failed, skipping',
            );
          }
        } catch (error) {
          engine.logger.warn({ error }, 'Error during image preprocessing, skipping');
        }
      })(),
    );
  }

  // Process videos (batch) - always uses File API
  if (filesByCategory.video.length > 0) {
    promises.push(
      (async () => {
        try {
          const fileIds = filesByCategory.video.map((f) => f.fileId);
          const fileNames = filesByCategory.video
            .map((f) => f.fileName)
            .filter(Boolean) as string[];

          // Use batch method if available, otherwise fall back to sequential processing
          if (engine.service.batchVideoUnderstanding) {
            const result = await engine.service.batchVideoUnderstanding!(user, {
              fileIds,
              query: enrichedQuery || undefined,
              mode: 'general',
            });
            if (result.success && result.data?.analysis) {
              results.push({
                type: 'video',
                fileId: fileIds.join(','),
                fileName: fileNames.length > 0 ? fileNames.join(', ') : undefined,
                analysis: result.data.analysis,
              });
            } else if (!result.success) {
              engine.logger.warn(
                { errCode: result.errCode, errMsg: result.errMsg },
                'Video batch preprocessing failed, skipping',
              );
            }
          } else if (engine.service.videoUnderstanding) {
            // Fallback to sequential processing
            for (const video of filesByCategory.video) {
              try {
                const result = await engine.service.videoUnderstanding!(user, {
                  fileId: video.fileId,
                  query: enrichedQuery || undefined,
                  mode: 'general',
                  contentType: video.contentType, // Pass MIME type to avoid re-querying
                });
                if (result.success && result.data?.analysis) {
                  results.push({
                    type: 'video',
                    fileId: video.fileId,
                    fileName: result.data.fileName || video.fileName,
                    analysis: result.data.analysis,
                  });
                }
              } catch (error) {
                engine.logger.warn(
                  { error, fileId: video.fileId },
                  'Error during video preprocessing, skipping',
                );
              }
            }
          }
        } catch (error) {
          engine.logger.warn({ error }, 'Error during video batch preprocessing, skipping');
        }
      })(),
    );
  }

  // Process audio files (batch) - always uses File API
  if (filesByCategory.audio.length > 0) {
    promises.push(
      (async () => {
        try {
          const fileIds = filesByCategory.audio.map((f) => f.fileId);
          const fileNames = filesByCategory.audio
            .map((f) => f.fileName)
            .filter(Boolean) as string[];

          // Use batch method if available, otherwise fall back to sequential processing
          if (engine.service.batchAudioUnderstanding) {
            const result = await engine.service.batchAudioUnderstanding!(user, {
              fileIds,
              query: enrichedQuery || undefined,
              mode: 'transcription',
            });
            if (result.success && result.data?.analysis) {
              results.push({
                type: 'audio',
                fileId: fileIds.join(','),
                fileName: fileNames.length > 0 ? fileNames.join(', ') : undefined,
                analysis: result.data.analysis,
              });
            } else if (!result.success) {
              engine.logger.warn(
                { errCode: result.errCode, errMsg: result.errMsg },
                'Audio batch preprocessing failed, skipping',
              );
            }
          } else if (engine.service.audioUnderstanding) {
            // Fallback to sequential processing
            for (const audio of filesByCategory.audio) {
              try {
                const result = await engine.service.audioUnderstanding!(user, {
                  fileId: audio.fileId,
                  query: enrichedQuery || undefined,
                  mode: 'transcription',
                  contentType: audio.contentType, // Pass MIME type to avoid re-querying
                });
                if (result.success && result.data?.analysis) {
                  results.push({
                    type: 'audio',
                    fileId: audio.fileId,
                    fileName: result.data.fileName || audio.fileName,
                    analysis: result.data.analysis,
                  });
                }
              } catch (error) {
                engine.logger.warn(
                  { error, fileId: audio.fileId },
                  'Error during audio preprocessing, skipping',
                );
              }
            }
          }
        } catch (error) {
          engine.logger.warn({ error }, 'Error during audio batch preprocessing, skipping');
        }
      })(),
    );
  }

  // Process documents (batch) - uses File API for >= 2MB, inline for < 2MB
  if (filesByCategory.document.length > 0) {
    promises.push(
      (async () => {
        try {
          const fileIds = filesByCategory.document.map((f) => f.fileId);
          const fileNames = filesByCategory.document
            .map((f) => f.fileName)
            .filter(Boolean) as string[];

          // Use batch method if available, otherwise fall back to sequential processing
          if (engine.service.batchDocumentProcessing) {
            const result = await engine.service.batchDocumentProcessing!(user, {
              fileIds,
              query: enrichedQuery || undefined,
              mode: 'summary',
            });
            if (result.success && result.data?.analysis) {
              results.push({
                type: 'document',
                fileId: fileIds.join(','),
                fileName: fileNames.length > 0 ? fileNames.join(', ') : undefined,
                analysis: result.data.analysis,
              });
            } else if (!result.success) {
              engine.logger.warn(
                { errCode: result.errCode, errMsg: result.errMsg },
                'Document batch preprocessing failed, skipping',
              );
            }
          } else if (engine.service.documentProcessing) {
            // Fallback to sequential processing
            for (const doc of filesByCategory.document) {
              try {
                const result = await engine.service.documentProcessing!(user, {
                  fileId: doc.fileId,
                  query: enrichedQuery || undefined,
                  mode: 'summary',
                  contentType: doc.contentType, // Pass MIME type to avoid re-querying
                });
                if (result.success && result.data?.analysis) {
                  results.push({
                    type: 'document',
                    fileId: doc.fileId,
                    fileName: result.data.fileName || doc.fileName,
                    analysis: result.data.analysis,
                  });
                }
              } catch (error) {
                engine.logger.warn(
                  { error, fileId: doc.fileId },
                  'Error during document preprocessing, skipping',
                );
              }
            }
          }
        } catch (error) {
          engine.logger.warn({ error }, 'Error during document batch preprocessing, skipping');
        }
      })(),
    );
  }

  // Wait for all processing to complete (parallel)
  await Promise.all(promises);

  return results;
}

export const preprocess = async (
  query: string,
  config: SkillRunnableConfig,
  engine: SkillEngine,
): Promise<PreprocessResult> => {
  const context = config?.configurable?.context ?? undefined;

  // Use shared query processor
  const { optimizedQuery, usedChatHistory, hasContext, remainingTokens } = await processQuery(
    query,
    config,
  );

  const needPrepareContext = hasContext && remainingTokens > 0;

  const result: PreprocessResult = {
    optimizedQuery,
    context: { files: [], results: [] },
    sources: [],
    usedChatHistory,
  };

  if (needPrepareContext) {
    result.context = await prepareContext(context, {
      maxTokens: remainingTokens,
      engine,
    });
  }

  // Unified multimodal preprocessing: process all media types through Gemini APIs
  // Skip files that have already been processed by upstream workflow nodes
  // (their analysis is already included in context.results)
  //
  // TODO: Future optimization - implement intent-based multimodal processing:
  // - Use lightweight heuristics or LLM to detect if user query relates to file analysis
  // - Only process files when user intent indicates analysis is needed
  // - Consider caching analysis results to avoid redundant processing
  const alreadyProcessedFileIds = getAlreadyProcessedFileIds(config);
  const filesByCategory = extractFileIdsByCategory(config, alreadyProcessedFileIds);
  if (hasMultimodalFiles(filesByCategory)) {
    result.multimodalInterpretations = await processMultimodalFiles(
      filesByCategory,
      query,
      result.context,
      config,
      engine,
    );
  }

  return result;
};
