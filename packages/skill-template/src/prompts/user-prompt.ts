import { ContextBlock } from '../scheduler/utils/context';

export interface BuildUserPromptOptions {
  hasVisionCapability?: boolean;
}

/**
 * Build instructions for using read_agent_result and read_tool_result tools.
 * These instructions guide the LLM on how to access full result content on-demand.
 */
const buildResultsMetaInstruction = (hasResultsMeta: boolean): string => {
  if (!hasResultsMeta) return '';

  return `
## Previous Results Access
The context contains metadata summaries of previous agent results (resultsMeta).
Each result includes:
- resultId: Unique identifier for the result
- title: Task description
- summary: **Unreliable preview** (~100 tokens truncated from the end, may be incomplete or miss key info)
- contentTokens: Size of full content (helps decide if worth reading)
- toolCallsMeta: List of tools used with their callId, toolName, and status
- outputFiles: Files generated by this result (may be empty for text-only results)

**To access full content:**
- Use \`read_agent_result(resultId)\` to get the complete AI output with tool call placeholders
- Use \`read_tool_result(resultId, callId)\` to get specific tool input/output details

**Critical - Summary is NOT reliable:**
- The summary is just a naive tail truncation, NOT a real summary
- It may miss important context, reasoning, or key details from earlier parts
- Do NOT make decisions based solely on the summary
- When in doubt, always call \`read_agent_result\` to get the full picture

**When to read full content:**
- contentTokens > 300: Almost always worth reading if task is related
- The task references or builds upon previous results
- You need specific details, data, or reasoning from the result
- Empty outputFiles with high contentTokens: Contains valuable text analysis

`;
};

export const buildUserPrompt = (
  query: string,
  context: ContextBlock,
  options?: BuildUserPromptOptions,
) => {
  if (!context || (!context.files?.length && !context.resultsMeta?.length)) {
    return query;
  }

  // Check if context has image files but model doesn't have vision capability
  const hasImageFiles = context.files?.some((f) => f.type?.startsWith('image/'));
  const hasVision = options?.hasVisionCapability ?? false;

  let visionWarning = '';
  if (hasImageFiles && !hasVision) {
    visionWarning =
      '\n\n**Note**: The context contains image files, but the current model does NOT have vision capability. You cannot see the image content. To process images, use `execute_code` with Python image libraries (e.g., PIL, opencv).\n';
  }

  // Add instruction for resultsMeta if present
  const resultsMetaInstruction = buildResultsMetaInstruction(!!context.resultsMeta?.length);

  return `User provided following context, please use them wisely to understand the task and solve the problem:
${resultsMetaInstruction}
\`\`\`json
${JSON.stringify(context, null, 2)}
\`\`\`
${visionWarning}
Question: ${query}`;
};
